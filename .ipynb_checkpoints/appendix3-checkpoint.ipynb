{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **工作备忘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2021-03-11**\n",
    "\n",
    "**待解决问题：使用线程，并行执行任务**\n",
    "\n",
    "+ 单线程 beat tracking 脚本已能凑合运行，接下来需要把 stream 数据读取任务另开一个线程快速执行\n",
    "\n",
    "+ 学会线程的使用后，记得把前面实时绘制频谱的代码也再修改一下\n",
    "\n",
    "+ 通过 pyaudio callback 模式，对于 **callback** 函数的用法终于有些感觉了。不过 pyaudio 的 callback 模式不能用，因为我要分析两个频率范围的数据，而 callback 函数输入与返回的都是 1 组数据，所以还是用 block 模式，然后放在单独一个线程中去执行\n",
    "\n",
    "\n",
    "**傅立叶转换过程中需注意的几项操作：**\n",
    "\n",
    "不同代码中，fft 的处理流程基本不会完全一致，前几天也花了很多时间试图找到尽可能完整标准的流程，makerpotal 上音频相关的那几篇教程和代码看来最完整可靠，如参考5\n",
    "\n",
    "+ 从 pyaudio stream 中读取出的数据，做**标准化处理**\n",
    "\n",
    "+ 使用 **hann window**\n",
    "\n",
    "+ **amplitude scaling**，即 fft 之后的 y 值除以 N（参考3）\n",
    "\n",
    "+ **single sideband** 处理，即 fft 之后 y 值乘 2（参考1、2）\n",
    "\n",
    "\n",
    "**要耐心阅读官方文档**\n",
    "\n",
    "PortAudio 官方文档对该工具的功能以及 stream 等相关概念的介绍有助于理解音频处理流程与操作（参考10）；matlab 官网 audiotoolbox 的相关文档也很有帮助，特别是有几张框架图很好（参考8、9）\n",
    "\n",
    "一开始总是根据别人的代码学习使用某个新工具，但要用好还是得去认真看文档，不过先后顺序也确实不好死板规定，在阅读与实操往复中进步。\n",
    "\n",
    "\n",
    "**最近重度使用的就是 matplotlib，numpy 和 pyaudio 这几个库，只依赖少量的库做事的感觉很好，清楚自己到底在做什么**\n",
    "\n",
    "\n",
    "**傅立叶转换的数学公式还是应该花时间搞清楚，只有这样才能彻底理解**\n",
    "\n",
    "\n",
    "参考：\n",
    "\n",
    "1. [can someone explaing the computation for double sided and single sided spectrum in fft() example](https://www.mathworks.com/matlabcentral/answers/356376-can-someone-explaing-the-computation-for-double-sided-and-single-sided-spectrum-in-fft-example)\n",
    "\n",
    "2. [Breaking down confusions over Fast Fourier Transform (FFT)](https://medium.com/analytics-vidhya/breaking-down-confusions-over-fast-fourier-transform-fft-1561a029b1ab)\n",
    "\n",
    "3. [FFT: scaling for correct amplitude](https://ch.mathworks.com/matlabcentral/answers/545066-fft-scaling-for-correct-amplitude)\n",
    "\n",
    "4. [An Intro to Threading in Python](https://realpython.com/intro-to-python-threading/#using-a-threadpoolexecutor)\n",
    "\n",
    "5. [Recording Stereo Audio on a Raspberry Pi](https://makersportal.com/blog/recording-stereo-audio-on-a-raspberry-pi)\n",
    "\n",
    "6. [Audio Processing with The QuadMic 4-Microphone Array on the Raspberry Pi](https://makersportal.com/blog/audio-processing-with-the-quadmic-4-microphone-array-on-the-raspberry-pi?rq=audio)\n",
    "\n",
    "7. [Realtime FFT Audio Visualization with Python](https://swharden.com/blog/2013-05-09-realtime-fft-audio-visualization-with-python/)\n",
    "\n",
    "8. [Audio I/O: Buffering, Latency, and Throughput](https://in.mathworks.com/help/audio/gs/audio-io-buffering-latency-and-throughput.html)\n",
    "\n",
    "9. [Get Started with Audio Toolbox](https://in.mathworks.com/help/audio/gs/real-time-audio-in-matlab.html)\n",
    "\n",
    "10. [PortAudio API Overview ](http://files.portaudio.com/docs/v19-doxydocs/api_overview.html)\n",
    "\n",
    "</br>\n",
    "\n",
    "## **2021-03-08**\n",
    "\n",
    "**折腾几天之后决定还是暂时搁置对 fft 后的 y 做 logscale 转化（dB）**\n",
    "\n",
    "主要原因是：将声音的振幅转为响度需要一个参考值，即一个最大振幅 y，然后根据公式 20\\*log10（y/ymax)可以求得相对分贝值，即最大响度为 0dB，响度越小，负值越大。但是现在我没有好的办法找到一个绝对的最大响度值，即使通过试验手动找到一个最大值（如 900），为了方便可视化，得到的结果还需进一步转换，所以还是干脆先搁置，直接用 fft 后的振幅值即可，只要记得还可以做 log 转化就行。另外需要注意的是，有些示例代码中做分贝转换时，直接用的 y，而非 y/ymax 这样的比值，除非他们的 y 是标准化之后的，即 ymax=1，否则就是有问题的。另外，**麦克风的敏感性和校准** 也是暂时先不考虑但要记得的问题。\n",
    "\n",
    "\n",
    "参考:  \n",
    "\n",
    "[Sound Intensity and Sound Level](https://courses.lumenlearning.com/physics/chapter/17-3-sound-intensity-and-sound-level/)\n",
    "\n",
    "[Decibels (dB) and Amplitude](https://blog.demofox.org/2015/04/14/decibels-db-and-amplitude/)\n",
    "\n",
    "[Recording Stereo Audio on a Raspberry Pi](https://makersportal.com/blog/recording-stereo-audio-on-a-raspberry-pi)\n",
    "\n",
    "[Audio Processing with The QuadMic 4-Microphone Array on the Raspberry Pi](https://makersportal.com/blog/audio-processing-with-the-quadmic-4-microphone-array-on-the-raspberry-pi)\n",
    "\n",
    "</br>\n",
    "\n",
    "## **2021-03-05**\n",
    "\n",
    "**今日问题：**\n",
    "\n",
    "**将 fft 之后的 y 转为 dB 并对应修改画图方式；麦克风需要检测与校准（未解决）**\n",
    "\n",
    "librosa load 音频文件时，默认 dtype='float32'，但是输出的 x 已经做了标准化，即除以2的31次方，所以是 float32 还是 float64 或 float16，并不会影响后续数据分析\n",
    "\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pyenv)",
   "language": "python",
   "name": "beatstracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
